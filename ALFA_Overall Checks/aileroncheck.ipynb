{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import statistics\n",
    "from abc import abstractmethod\n",
    "\n",
    "import colorsys\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import statistics\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 'no anomaly.csv'\n",
    "f1 = 'engine.csv'\n",
    "f2 = 'elevator.csv'\n",
    "f3 = 'aileron.csv'\n",
    "f4 = 'rudder.csv'\n",
    "\n",
    "base_df = pd.read_csv(f0, header=0, index_col=None)\n",
    "engine1_df = pd.read_csv(f1, header=0, index_col=None)\n",
    "elevator1_df = pd.read_csv(f2, header=0, index_col=None)\n",
    "aileron1_df = pd.read_csv(f3, header=0, index_col=None)\n",
    "rudder1_df = pd.read_csv(f4, header=0, index_col=None)\n",
    "\n",
    "df_list = [base_df, engine1_df, elevator1_df, aileron1_df, rudder1_df]\n",
    "\n",
    "for df in df_list:\n",
    "\n",
    "    df['airspeedchange'] = df['Airspeed']- df['Airspeed'].shift(1)\n",
    "    df['airspeedchange'].fillna(0, inplace=True)\n",
    "\n",
    "anomaly_list = aileron1_df['Anomaly'].tolist()\n",
    "\n",
    "base_df = base_df[['Roll', 'Pitch', 'Yaw', 'Airspeed', 'VelocityX', 'VelocityY', 'VelocityZ', 'airspeedchange']]\n",
    "clustering_engine_df = engine1_df[['Roll', 'Pitch', 'Yaw', 'Airspeed', 'VelocityX', 'VelocityY', 'VelocityZ', 'airspeedchange']]\n",
    "clustering_elevator1_df = elevator1_df[['Roll', 'Pitch', 'Yaw', 'Airspeed', 'VelocityX', 'VelocityY', 'VelocityZ', 'airspeedchange']]\n",
    "clustering_aileron1_df = aileron1_df[['Roll', 'Pitch', 'Yaw', 'Airspeed', 'VelocityX', 'VelocityY', 'VelocityZ', 'airspeedchange']]\n",
    "clustering_rudder_df = rudder1_df[['Roll', 'Pitch', 'Yaw', 'Airspeed', 'VelocityX', 'VelocityY', 'VelocityZ', 'airspeedchange']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2349"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_list.count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the 5 models\n",
    "\n",
    "kmeans = KMeans(init=\"random\", n_clusters=2, n_init=10, random_state=1)\n",
    "kmeans.fit(base_df)\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=14, contamination=\"auto\",novelty=True)\n",
    "lof.fit(base_df)\n",
    "\n",
    "nu = 0.1\n",
    "kernel = 'rbf'\n",
    "gamma = 'scale'\n",
    "\n",
    "model = OneClassSVM(nu=nu, kernel=kernel, gamma=gamma)\n",
    "model.fit(base_df)\n",
    "\n",
    "db = DBSCAN(eps = 0.78).fit(base_df)\n",
    "\n",
    "optics_clustering = OPTICS(min_samples = 50).fit(base_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_checker(datapoint):\n",
    "    rules_broken = 0\n",
    "    if datapoint[\"Roll\"] > 47.3 or datapoint[\"Roll\"] < -50:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"Pitch\"] > 22.93 or datapoint[\"Pitch\"] < -19.3:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"Yaw\"] > 179.2 or datapoint[\"Yaw\"] < -177.3:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"Airspeed\"] > 24.29 or datapoint[\"Airspeed\"] < 12.48:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"VelocityX\"] > 19.73 or datapoint[\"VelocityX\"] < -17.05:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"VelocityY\"] > 21.4 or datapoint[\"VelocityY\"] < -18.26:\n",
    "        rules_broken += 1\n",
    "\n",
    "    if datapoint[\"VelocityZ\"] > 5.3 or datapoint[\"VelocityZ\"] < -8.6:\n",
    "        rules_broken += 1\n",
    "\n",
    "    return rules_broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>aileron<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m base_df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m     26\u001b[0m aileron1_df2 \u001b[38;5;241m=\u001b[39m clustering_aileron1_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 27\u001b[0m aileron1_df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclustering_aileron1_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m centroids \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_\n\u001b[1;32m     31\u001b[0m original_distances \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py:1058\u001b[0m, in \u001b[0;36m_BaseKMeans.predict\u001b[0;34m(self, X, sample_weight)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict the closest cluster each sample in X belongs to.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \n\u001b[1;32m   1038\u001b[0m \u001b[39mIn the vector quantization literature, `cluster_centers_` is called\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[39m    Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1058\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_test_data(X)\n\u001b[1;32m   1059\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m labels \u001b[39m=\u001b[39m _labels_inertia_threadpool_limit(\n\u001b[1;32m   1062\u001b[0m     X,\n\u001b[1;32m   1063\u001b[0m     sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     return_inertia\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1067\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py:934\u001b[0m, in \u001b[0;36m_BaseKMeans._check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_test_data\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 934\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    935\u001b[0m         X,\n\u001b[1;32m    936\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    937\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    938\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m    939\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    940\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    941\u001b[0m     )\n\u001b[1;32m    942\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "aileron_rule_alerts = []\n",
    "\n",
    "for i in range (len(aileron1_df)):\n",
    "    alerts = 0\n",
    "\n",
    "    alerts += (rule_checker(aileron1_df.iloc[i]))\n",
    "    \n",
    "    aileron_rule_alerts.append(alerts)\n",
    "    \n",
    "count = 0\n",
    "for value in aileron_rule_alerts:\n",
    "    if value >0:\n",
    "        count +=1\n",
    "\n",
    "\n",
    "#predict for aileron\n",
    "\n",
    "aileron_kmeans = []\n",
    "aileron_lof = []\n",
    "aileron_svm = []\n",
    "aileron_db = []\n",
    "aileron_optics = []\n",
    "\n",
    "base_df2 = base_df.copy()\n",
    "base_df2['cluster'] = kmeans.labels_\n",
    "aileron1_df2 = clustering_aileron1_df.copy()\n",
    "aileron1_df2['cluster'] = kmeans.predict(clustering_aileron1_df)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "original_distances = []\n",
    "for i in range(len(base_df)):\n",
    "    centroid = centroids[int(base_df2.iloc[i]['cluster'])]\n",
    "    distance = np.sqrt(np.sum((base_df.iloc[i] - centroid)**2))\n",
    "    original_distances.append(distance)\n",
    "\n",
    "original_mean = sum(original_distances)/len(original_distances)\n",
    "\n",
    "original_std = np.std(original_distances)\n",
    "\n",
    "threshold = original_mean + 3* original_std\n",
    "\n",
    "for i in range(len(clustering_aileron1_df)):\n",
    "    centroid = centroids[int(aileron1_df2.iloc[i]['cluster'])]\n",
    "    distance = np.sqrt(np.sum((clustering_aileron1_df.iloc[i] - centroid)**2))\n",
    "    if distance > threshold:\n",
    "        aileron_kmeans.append(-1)\n",
    "    else:\n",
    "        aileron_kmeans.append(1)\n",
    "\n",
    "\n",
    "for i in range(clustering_aileron1_df.shape[0]):\n",
    "    prediction = lof.predict(clustering_aileron1_df.iloc[[i]])\n",
    "    for value in prediction:\n",
    "        aileron_lof.append(value)\n",
    "\n",
    "for i in range(clustering_aileron1_df.shape[0]):\n",
    "    prediction = model.predict(clustering_aileron1_df.iloc[[i]])\n",
    "    for value in prediction:\n",
    "        aileron_svm.append(value)\n",
    "\n",
    "for value in db.fit_predict(clustering_aileron1_df):\n",
    "    aileron_db.append(value)\n",
    "\n",
    "for value in optics_clustering.fit_predict(clustering_aileron1_df):\n",
    "    aileron_optics.append(value)\n",
    "\n",
    "\n",
    "#get predictions for aileron using voting\n",
    "\n",
    "final_aileron_predictions = []\n",
    "\n",
    "for i in range (len(aileron1_df)):\n",
    "    predictions = [aileron_kmeans[i], aileron_lof[i], aileron_svm[i], aileron_db[i], aileron_optics[i]]\n",
    "    final_aileron_predictions.append(max(set(predictions), key=predictions.count))\n",
    "    \n",
    "overall_aileron_count = 0\n",
    "\n",
    "for i in range(len(aileron1_df)):\n",
    "    if final_aileron_predictions[i] <0 or aileron_rule_alerts[i] > 0:\n",
    "        overall_aileron_count+=1\n",
    "\n",
    "print(\"For aileron, out of the\", len(aileron1_df), \"anomalies\", overall_aileron_count ,\"were detected, which is\", overall_aileron_count/len(aileron1_df)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2194\n"
     ]
    }
   ],
   "source": [
    "unsupervised_count = 0\n",
    "\n",
    "for i in range(len(aileron1_df)):\n",
    "    if final_aileron_predictions[i] < 0:\n",
    "        unsupervised_count += 1\n",
    "\n",
    "print(unsupervised_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2506\n"
     ]
    }
   ],
   "source": [
    "rule_count = 0\n",
    "\n",
    "for i in range(len(aileron1_df)):\n",
    "    if aileron_rule_alerts[i] > 0:\n",
    "        rule_count += 1\n",
    "\n",
    "print(rule_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
